{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机数种子已设置为: 42\n",
      "当前设备: cuda\n",
      "--- 步骤1: 正在加载和预处理数据 ---\n",
      "正在将时间序列转换为监督学习格式...\n",
      "数据准备完成。\n",
      "\n",
      "--- 步骤2: 实例化采用u,v缩放RPE的ICIAL模型 ---\n",
      "\n",
      "--- 模型架构摘要 ---\n",
      "=================================================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Mult-Adds\n",
      "=================================================================================================================================================\n",
      "ICIAL_UV_RPE_Model                            [64, 96, 1]               [64, 13]                  --                        --\n",
      "├─EnhancedHighFrequencyModel: 1-1             [64, 96, 1]               [64, 128]                 --                        --\n",
      "│    └─Conv1d: 2-1                            [64, 1, 96]               [64, 128, 96]             512                       3,145,728\n",
      "│    └─GRU: 2-2                               [64, 96, 128]             [64, 96, 256]             494,592                   3,038,773,248\n",
      "│    └─Linear: 2-3                            [64, 96, 256]             [64, 96, 128]             32,896                    2,105,344\n",
      "│    └─GRU: 2-4                               [64, 96, 5]               [64, 96, 256]             103,680                   637,009,920\n",
      "│    └─Linear: 2-5                            [64, 96, 256]             [64, 96, 128]             32,896                    2,105,344\n",
      "│    └─RelativePositionBias: 2-6              --                        [1, 8, 96, 96]            --                        --\n",
      "│    │    └─Embedding: 3-1                    [96, 96]                  [96, 96, 8]               256                       24,576\n",
      "│    └─ModuleList: 2-7                        --                        --                        --                        --\n",
      "│    │    └─ModuleDict: 3-2                   --                        --                        396,560                   --\n",
      "│    │    └─ModuleDict: 3-3                   --                        --                        396,560                   --\n",
      "├─LowFrequencyLSTM: 1-2                       [64, 96, 1]               [64, 128]                 --                        --\n",
      "│    └─LSTM: 2-8                              [64, 96, 1]               [64, 96, 128]             331,264                   2,035,286,016\n",
      "├─Sequential: 1-3                             [64, 256]                 [64, 256]                 --                        --\n",
      "│    └─Linear: 2-9                            [64, 256]                 [64, 256]                 65,792                    4,210,688\n",
      "│    └─GELU: 2-10                             [64, 256]                 [64, 256]                 --                        --\n",
      "│    └─Dropout: 2-11                          [64, 256]                 [64, 256]                 --                        --\n",
      "├─ModuleDict: 1-4                             --                        --                        --                        --\n",
      "│    └─Linear: 2-12                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
      "│    └─Linear: 2-13                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
      "│    └─Linear: 2-14                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
      "│    └─Linear: 2-15                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
      "=================================================================================================================================================\n",
      "Total params: 1,868,372\n",
      "Trainable params: 1,868,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 5.77\n",
      "=================================================================================================================================================\n",
      "Input size (MB): 0.17\n",
      "Forward/backward pass size (MB): 277.57\n",
      "Params size (MB): 6.94\n",
      "Estimated Total Size (MB): 284.69\n",
      "=================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "=================================================================================================================================================\n",
       "ICIAL_UV_RPE_Model                            [64, 96, 1]               [64, 13]                  --                        --\n",
       "├─EnhancedHighFrequencyModel: 1-1             [64, 96, 1]               [64, 128]                 --                        --\n",
       "│    └─Conv1d: 2-1                            [64, 1, 96]               [64, 128, 96]             512                       3,145,728\n",
       "│    └─GRU: 2-2                               [64, 96, 128]             [64, 96, 256]             494,592                   3,038,773,248\n",
       "│    └─Linear: 2-3                            [64, 96, 256]             [64, 96, 128]             32,896                    2,105,344\n",
       "│    └─GRU: 2-4                               [64, 96, 5]               [64, 96, 256]             103,680                   637,009,920\n",
       "│    └─Linear: 2-5                            [64, 96, 256]             [64, 96, 128]             32,896                    2,105,344\n",
       "│    └─RelativePositionBias: 2-6              --                        [1, 8, 96, 96]            --                        --\n",
       "│    │    └─Embedding: 3-1                    [96, 96]                  [96, 96, 8]               256                       24,576\n",
       "│    └─ModuleList: 2-7                        --                        --                        --                        --\n",
       "│    │    └─ModuleDict: 3-2                   --                        --                        396,560                   --\n",
       "│    │    └─ModuleDict: 3-3                   --                        --                        396,560                   --\n",
       "├─LowFrequencyLSTM: 1-2                       [64, 96, 1]               [64, 128]                 --                        --\n",
       "│    └─LSTM: 2-8                              [64, 96, 1]               [64, 96, 128]             331,264                   2,035,286,016\n",
       "├─Sequential: 1-3                             [64, 256]                 [64, 256]                 --                        --\n",
       "│    └─Linear: 2-9                            [64, 256]                 [64, 256]                 65,792                    4,210,688\n",
       "│    └─GELU: 2-10                             [64, 256]                 [64, 256]                 --                        --\n",
       "│    └─Dropout: 2-11                          [64, 256]                 [64, 256]                 --                        --\n",
       "├─ModuleDict: 1-4                             --                        --                        --                        --\n",
       "│    └─Linear: 2-12                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
       "│    └─Linear: 2-13                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
       "│    └─Linear: 2-14                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
       "│    └─Linear: 2-15                           [64, 256]                 [64, 13]                  3,341                     213,824\n",
       "=================================================================================================================================================\n",
       "Total params: 1,868,372\n",
       "Trainable params: 1,868,372\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.77\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 277.57\n",
       "Params size (MB): 6.94\n",
       "Estimated Total Size (MB): 284.69\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from torchinfo import summary\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# 0. 设置随机数种子\n",
    "# =============================================================================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"随机数种子已设置为: {seed}\")\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "set_seed(GLOBAL_SEED)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 文件路径与超参数设置\n",
    "# =============================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前设备: {device}\")\n",
    "\n",
    "HIGH_FREQ_DATA_PATH = r'D:\\python-deeplearning\\FirstPaper\\PVTimeSeriesLearing\\project\\小论文1-基于ICEEMDAN分解的时序高维变化的短期光伏功率预测模型\\CEEMAN-PosConv1dbiLSTM-LSTM\\模型代码流程\\完整的模型代码流程 copy 2\\MC-Dropout-test\\数据集\\DKASC\\DKASC_high_frequency_data.csv'\n",
    "LOW_FREQ_DATA_PATH = r'D:\\python-deeplearning\\FirstPaper\\PVTimeSeriesLearing\\project\\小论文1-基于ICEEMDAN分解的时序高维变化的短期光伏功率预测模型\\CEEMAN-PosConv1dbiLSTM-LSTM\\模型代码流程\\完整的模型代码流程 copy 2\\MC-Dropout-test\\数据集\\DKASC\\DKASC_low_frequency_data.csv'\n",
    "ORIGINAL_DATA_PATH = r'D:\\python-deeplearning\\FirstPaper\\PVTimeSeriesLearing\\project\\小论文1-基于ICEEMDAN分解的时序高维变化的短期光伏功率预测模型\\CEEMAN-PosConv1dbiLSTM-LSTM\\模型代码流程\\完整的模型代码流程 copy 2\\MC-Dropout-test\\数据集\\DKASC\\DKASC.csv'\n",
    "MODEL_FILE_PATH = 'icial_uv_rpe_model.pth' # 新模型保存路径\n",
    "\n",
    "# --- 超参数 ---\n",
    "N_STEPS_IN, N_STEPS_OUT = 96, 24\n",
    "TARGET_STEPS = [3, 6, 12, 24]\n",
    "HIGH_FREQ_FEATURES = 1\n",
    "WEATHER_FEATURES = 5\n",
    "LOW_FREQ_FEATURES = 1\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "PATIENCE = 10\n",
    "\n",
    "# --- 模型结构参数 ---\n",
    "EMBED_DIM = 128\n",
    "GRU_LAYERS = 2 \n",
    "LSTM_LAYERS = 3\n",
    "NUM_HEADS = 8\n",
    "DROPOUT = 0.2\n",
    "TRANSFORMER_LAYERS = 2\n",
    "RELATIVE_POSITION_BUCKETS = 32\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 数据预处理函数 \n",
    "# =============================================================================\n",
    "def time_series_to_supervised_mimo(data, n_in=96, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if isinstance(data, list) else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    orig_names = df.columns\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (orig_names[j], i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        names += [('%s(t%s%d)' % (orig_names[j], '' if i==0 else '+', i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 核心模型架构 (应用u,v缩放的RPE)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 模块 1: 相对位置偏置生成器 ---\n",
    "class RelativePositionBias(nn.Module):\n",
    "    def __init__(self, num_buckets, max_distance, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_buckets = num_buckets\n",
    "        self.max_distance = max_distance\n",
    "        self.num_heads = num_heads\n",
    "        self.relative_attention_bias = nn.Embedding(self.num_buckets, self.num_heads)\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
    "        ret = 0\n",
    "        n = -relative_position\n",
    "        if bidirectional:\n",
    "            num_buckets //= 2\n",
    "            ret += (n < 0).to(torch.long) * num_buckets\n",
    "            n = torch.abs(n)\n",
    "        else:\n",
    "            n = torch.max(n, torch.zeros_like(n))\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = n < max_exact\n",
    "        val_if_large = max_exact + (torch.log(n.float() / max_exact) / np.log(max_distance / max_exact) * (num_buckets - max_exact)).to(torch.long)\n",
    "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
    "        ret += torch.where(is_small, n, val_if_large)\n",
    "        return ret\n",
    "\n",
    "    def forward(self, seq_len, device):\n",
    "        q_pos = torch.arange(seq_len, dtype=torch.long, device=device)\n",
    "        k_pos = torch.arange(seq_len, dtype=torch.long, device=device)\n",
    "        rel_pos = k_pos[None, :] - q_pos[:, None]\n",
    "        rp_bucket = self._relative_position_bucket(rel_pos, bidirectional=True, num_buckets=self.num_buckets, max_distance=self.max_distance)\n",
    "        bias = self.relative_attention_bias(rp_bucket)\n",
    "        return bias.permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "# --- 模块 2: 集成了u,v缩放的RPE的Transformer块 ---\n",
    "class UV_ScaledRPE_Block(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        assert self.head_dim * self.num_heads == self.d_model, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.qkv_proj = nn.Linear(d_model, d_model * 3)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ffn = nn.Sequential(nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout), nn.Linear(d_ff, d_model))\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # --- 核心修改: 引入u和v对应的可学习缩放参数 ---\n",
    "        self.rpe_scale_u = nn.Parameter(torch.ones(1, num_heads, 1, 1))\n",
    "        self.rpe_scale_v = nn.Parameter(torch.ones(1, num_heads, 1, 1))\n",
    "\n",
    "    def forward(self, x, bias):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        B, L, D = x.shape\n",
    "        q, k, v = self.qkv_proj(x).chunk(3, dim=-1)\n",
    "\n",
    "        q = q.view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, L, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        \n",
    "        # --- 应用 u,v 缩放逻辑 ---\n",
    "        final_bias = (bias * self.rpe_scale_u) + (bias * self.rpe_scale_v)\n",
    "        attn_scores = attn_scores + final_bias\n",
    "        \n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_probs = self.attn_dropout(attn_probs)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_probs, v).transpose(1, 2).contiguous().view(B, L, D)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        x = residual + self.dropout1(attn_output)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = residual + self.dropout2(x)\n",
    "        return x\n",
    "\n",
    "# --- 模块 3: 重构的高频分支  ---\n",
    "class EnhancedHighFrequencyModel(nn.Module):\n",
    "    def __init__(self, power_dim, weather_dim, hidden_dim, n_gru_layers, num_heads, dropout, n_transformer_blocks, num_pos_buckets):\n",
    "        super().__init__()\n",
    "        self.power_conv = nn.Conv1d(in_channels=power_dim, out_channels=hidden_dim, kernel_size=3, padding=1)\n",
    "        self.power_bigru = nn.GRU(hidden_dim, hidden_dim, n_gru_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.power_fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "        self.weather_bigru = nn.GRU(weather_dim, hidden_dim, 1, batch_first=True, bidirectional=True)\n",
    "        self.weather_fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "        self.relative_pos_bias_generator = RelativePositionBias(num_buckets=num_pos_buckets, max_distance=N_STEPS_IN, num_heads=num_heads)\n",
    "        \n",
    "        self.transformer_blocks = nn.ModuleList()\n",
    "        for _ in range(n_transformer_blocks):\n",
    "            # 每个Transformer块包含一个自注意力和一个交叉注意力\n",
    "            block = nn.ModuleDict({\n",
    "                'uv_scaled_rpe_self_attn': UV_ScaledRPE_Block(d_model=hidden_dim, num_heads=num_heads, d_ff=hidden_dim*4, dropout=dropout),\n",
    "                'norm_cross_attn': nn.LayerNorm(hidden_dim),\n",
    "                'cross_attn': nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, dropout=dropout, batch_first=True),\n",
    "                'dropout_cross_attn': nn.Dropout(dropout),\n",
    "                'norm_ffn_cross': nn.LayerNorm(hidden_dim),\n",
    "                'ffn_cross': nn.Sequential(nn.Linear(hidden_dim, hidden_dim * 4), nn.GELU(), nn.Dropout(dropout), nn.Linear(hidden_dim * 4, hidden_dim)),\n",
    "                'dropout_ffn_cross': nn.Dropout(dropout)\n",
    "            })\n",
    "            self.transformer_blocks.append(block)\n",
    "\n",
    "    def forward(self, x_high_freq, x_weather):\n",
    "        h_power = self.power_fc(self.power_bigru(self.power_conv(x_high_freq.permute(0, 2, 1)).permute(0, 2, 1))[0])\n",
    "        h_weather = self.weather_fc(self.weather_bigru(x_weather)[0])\n",
    "        \n",
    "        relative_bias = self.relative_pos_bias_generator(h_power.size(1), device=h_power.device)\n",
    "\n",
    "        processed_power = h_power\n",
    "        for block in self.transformer_blocks:\n",
    "            # 1. 带u,v缩放的RPE自注意力 \n",
    "            processed_power = block['uv_scaled_rpe_self_attn'](processed_power, relative_bias)\n",
    "\n",
    "            # 2. 交叉注意力 \n",
    "            residual = processed_power\n",
    "            norm_power_for_cross = block['norm_cross_attn'](processed_power)\n",
    "            cross_attn_output, _ = block['cross_attn'](query=norm_power_for_cross, key=h_weather, value=h_weather)\n",
    "            processed_power = residual + block['dropout_cross_attn'](cross_attn_output)\n",
    "            \n",
    "            # 3. 交叉注意力后的FFN\n",
    "            residual = processed_power\n",
    "            norm_power_for_ffn = block['norm_ffn_cross'](processed_power)\n",
    "            ffn_output = block['ffn_cross'](norm_power_for_ffn)\n",
    "            processed_power = residual + block['dropout_ffn_cross'](ffn_output)\n",
    "            \n",
    "        return processed_power[:, -1, :]\n",
    "\n",
    "# --- 低频分支  ---\n",
    "class LowFrequencyLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_lstm_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_lstm_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "    def forward(self, x_low_freq):\n",
    "        _, (h_n, _) = self.lstm(x_low_freq)\n",
    "        return h_n[-1]\n",
    "\n",
    "# --- 顶层模型  ---\n",
    "class ICIAL_UV_RPE_Model(nn.Module):\n",
    "    def __init__(self, target_steps_names, power_dim, weather_dim, low_freq_dim, embed_dim, n_gru_layers, n_lstm_layers, num_heads, dropout, transformer_layers, num_pos_buckets):\n",
    "        super().__init__()\n",
    "        self.target_steps_names = target_steps_names\n",
    "        self.quantiles_to_predict = sorted(list(set([0.5, 0.025, 0.975, 0.05, 0.95, 0.1, 0.9, 0.15, 0.85, 0.2, 0.8, 0.075, 0.925])))\n",
    "        \n",
    "        self.high_freq_branch = EnhancedHighFrequencyModel(power_dim, weather_dim, embed_dim, n_gru_layers, num_heads, dropout, transformer_layers, num_pos_buckets)\n",
    "        self.low_freq_branch = LowFrequencyLSTM(low_freq_dim, embed_dim, n_lstm_layers, dropout)\n",
    "        \n",
    "        self.fusion_mlp = nn.Sequential(nn.Linear(embed_dim * 2, embed_dim * 2), nn.GELU(), nn.Dropout(dropout))\n",
    "        \n",
    "        self.quantile_output_heads = nn.ModuleDict()\n",
    "        for name in self.target_steps_names:\n",
    "            self.quantile_output_heads[name] = nn.Linear(embed_dim * 2, len(self.quantiles_to_predict))\n",
    "\n",
    "    def forward(self, x_high, x_weather, x_low):\n",
    "        shared_high_freq_features = self.high_freq_branch(x_high, x_weather)\n",
    "        shared_low_freq_features = self.low_freq_branch(x_low)\n",
    "        combined_features = torch.cat([shared_high_freq_features, shared_low_freq_features], dim=1)\n",
    "        final_features = self.fusion_mlp(combined_features)\n",
    "        return_dict = {name: self.quantile_output_heads[name](final_features) for name in self.target_steps_names}\n",
    "        return return_dict\n",
    "\n",
    "# --- 分位数损失函数  ---\n",
    "def quantile_loss(y_true, y_pred_quantiles, quantiles_to_predict):\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles_to_predict):\n",
    "        y_pred_q = y_pred_quantiles[:, i]\n",
    "        errors = y_true - y_pred_q\n",
    "        loss = torch.max(q * errors, (q - 1) * errors)\n",
    "        losses.append(loss.mean())\n",
    "    return torch.stack(losses).sum()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. 数据加载与准备 \n",
    "# =============================================================================\n",
    "print(\"--- 步骤1: 正在加载和预处理数据 ---\")\n",
    "try:\n",
    "    high_freq_df = pd.read_csv(HIGH_FREQ_DATA_PATH).interpolate()\n",
    "    low_freq_df = pd.read_csv(LOW_FREQ_DATA_PATH).interpolate()\n",
    "    original_df = pd.read_csv(ORIGINAL_DATA_PATH).interpolate()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误：找不到数据文件！请检查路径设置。{e}\"); exit()\n",
    "\n",
    "weather_df = original_df[['Temp','Humidity','GHI','DHI','Rainfall']]\n",
    "power_df = original_df[['Power']]\n",
    "\n",
    "print(\"正在将时间序列转换为监督学习格式...\")\n",
    "processed_power = time_series_to_supervised_mimo(power_df, N_STEPS_IN, N_STEPS_OUT)\n",
    "processed_high = time_series_to_supervised_mimo(high_freq_df, N_STEPS_IN, N_STEPS_OUT)\n",
    "processed_low = time_series_to_supervised_mimo(low_freq_df, N_STEPS_IN, N_STEPS_OUT)\n",
    "processed_weather = time_series_to_supervised_mimo(weather_df, N_STEPS_IN, N_STEPS_OUT)\n",
    "\n",
    "common_index = processed_power.index.intersection(processed_high.index).intersection(processed_low.index).intersection(processed_weather.index)\n",
    "processed_power, processed_high, processed_low, processed_weather = [df.loc[common_index] for df in [processed_power, processed_high, processed_low, processed_weather]]\n",
    "\n",
    "# **修复**：确保y_cols的格式化字符串与`time_series_to_supervised_mimo`函数生成的列名完全匹配\n",
    "y_cols = [f'Power(t{\"\" if s-1==0 else f\"+{s-1}\"})' for s in TARGET_STEPS] \n",
    "y = processed_power[y_cols].values\n",
    "\n",
    "X_high = processed_high[[c for c in processed_high.columns if '(t-' in c]].values.reshape(-1, N_STEPS_IN, HIGH_FREQ_FEATURES)\n",
    "X_weather = processed_weather[[c for c in processed_weather.columns if '(t-' in c]].values.reshape(-1, N_STEPS_IN, WEATHER_FEATURES)\n",
    "X_low = processed_low[[c for c in processed_low.columns if '(t-' in c]].values.reshape(-1, N_STEPS_IN, LOW_FREQ_FEATURES)\n",
    "\n",
    "train_size = int(len(y) * 0.8); val_size = int(len(y) * 0.15)\n",
    "def split_data(data): return data[:train_size], data[train_size:train_size+val_size], data[train_size+val_size:]\n",
    "train_X_high, val_X_high, test_X_high = split_data(X_high)\n",
    "train_X_weather, val_X_weather, test_X_weather = split_data(X_weather)\n",
    "train_X_low, val_X_low, test_X_low = split_data(X_low)\n",
    "train_y, val_y, test_y = split_data(y)\n",
    "\n",
    "scaler_high = MinMaxScaler(); scaler_weather = MinMaxScaler(); scaler_low = MinMaxScaler()\n",
    "scalers_y = {f't_plus_{s}': MinMaxScaler() for s in TARGET_STEPS}\n",
    "\n",
    "def scale_3d_data(train, val, test, scaler):\n",
    "    train_s = scaler.fit_transform(train.reshape(-1, train.shape[-1])).reshape(train.shape)\n",
    "    val_s = scaler.transform(val.reshape(-1, val.shape[-1])).reshape(val.shape)\n",
    "    test_s = scaler.transform(test.reshape(-1, test.shape[-1])).reshape(test.shape)\n",
    "    return train_s, val_s, test_s\n",
    "\n",
    "train_X_high_s, val_X_high_s, test_X_high_s = scale_3d_data(train_X_high, val_X_high, test_X_high, scaler_high)\n",
    "train_X_weather_s, val_X_weather_s, test_X_weather_s = scale_3d_data(train_X_weather, val_X_weather, test_X_weather, scaler_weather)\n",
    "train_X_low_s, val_X_low_s, test_X_low_s = scale_3d_data(train_X_low, val_X_low, test_X_low, scaler_low)\n",
    "\n",
    "train_y_s_list, val_y_s_list, test_y_s_list = [], [], []\n",
    "for i, s in enumerate(TARGET_STEPS):\n",
    "    name = f't_plus_{s}'\n",
    "    train_y_s_list.append(scalers_y[name].fit_transform(train_y[:, i:i+1]).flatten())\n",
    "    val_y_s_list.append(scalers_y[name].transform(val_y[:, i:i+1]).flatten())\n",
    "    test_y_s_list.append(scalers_y[name].transform(test_y[:, i:i+1]).flatten())\n",
    "\n",
    "print(\"数据准备完成。\")\n",
    "\n",
    "train_y_tensors = [torch.from_numpy(v).float() for v in train_y_s_list]\n",
    "val_y_tensors = [torch.from_numpy(v).float() for v in val_y_s_list]\n",
    "test_y_tensors = [torch.from_numpy(v).float() for v in test_y_s_list]\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_X_high_s).float(), torch.from_numpy(train_X_weather_s).float(), torch.from_numpy(train_X_low_s).float(), *train_y_tensors)\n",
    "val_data = TensorDataset(torch.from_numpy(val_X_high_s).float(), torch.from_numpy(val_X_weather_s).float(), torch.from_numpy(val_X_low_s).float(), *val_y_tensors)\n",
    "test_data_for_loader = TensorDataset(torch.from_numpy(test_X_high_s).float(), torch.from_numpy(test_X_weather_s).float(), torch.from_numpy(test_X_low_s).float(), *test_y_tensors) \n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data_for_loader, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. 模型实例化、优化器定义与框架摘要\n",
    "# =============================================================================\n",
    "print(\"\\n--- 步骤2: 实例化采用u,v缩放RPE的ICIAL模型 ---\")\n",
    "\n",
    "model = ICIAL_UV_RPE_Model(\n",
    "    target_steps_names=[f't_plus_{s}' for s in TARGET_STEPS],\n",
    "    power_dim=HIGH_FREQ_FEATURES, weather_dim=WEATHER_FEATURES, low_freq_dim=LOW_FREQ_FEATURES,\n",
    "    embed_dim=EMBED_DIM, n_gru_layers=GRU_LAYERS, n_lstm_layers=LSTM_LAYERS,\n",
    "    num_heads=NUM_HEADS, dropout=DROPOUT, transformer_layers=TRANSFORMER_LAYERS,\n",
    "    num_pos_buckets=RELATIVE_POSITION_BUCKETS\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=PATIENCE//2, factor=0.5, verbose=True)\n",
    "\n",
    "print(\"\\n--- 模型架构摘要 ---\")\n",
    "summary(model, input_size=[ (BATCH_SIZE, N_STEPS_IN, HIGH_FREQ_FEATURES), (BATCH_SIZE, N_STEPS_IN, WEATHER_FEATURES), (BATCH_SIZE, N_STEPS_IN, LOW_FREQ_FEATURES)], col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型可训练参数总数: 1,868,372\n",
      "模型可训练参数量: 7.13 MB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. 训练和验证循环\n",
    "# =============================================================================\n",
    "# 计算模型总参数量\n",
    "#模型可训练参数量: 7.75 MB\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"模型可训练参数总数: {total_params:,}\")\n",
    "\n",
    "# 将参数量转换为MB (新增)\n",
    "# 假设每个参数占用4字节（即torch.float32）\n",
    "params_in_mb = (total_params * 4) / (1024 * 1024)\n",
    "print(f\"模型可训练参数量: {params_in_mb:.2f} MB\") # 格式化为两位小数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 步骤3: 开始模型训练 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 训练: 100%|██████████| 1302/1302 [00:58<00:00, 22.42it/s]\n",
      "Epoch 1 验证: 100%|██████████| 245/245 [00:02<00:00, 82.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, 训练损失: 0.9149, 验证损失: 0.4970, 耗时: 61.08s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 训练: 100%|██████████| 1302/1302 [00:57<00:00, 22.83it/s]\n",
      "Epoch 2 验证: 100%|██████████| 245/245 [00:03<00:00, 79.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, 训练损失: 0.5282, 验证损失: 0.4568, 耗时: 60.12s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 训练: 100%|██████████| 1302/1302 [00:56<00:00, 22.89it/s]\n",
      "Epoch 3 验证: 100%|██████████| 245/245 [00:02<00:00, 82.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, 训练损失: 0.4516, 验证损失: 0.3933, 耗时: 59.86s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 训练: 100%|██████████| 1302/1302 [00:56<00:00, 22.90it/s]\n",
      "Epoch 4 验证: 100%|██████████| 245/245 [00:02<00:00, 82.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, 训练损失: 0.4162, 验证损失: 0.3983, 耗时: 59.84s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 训练: 100%|██████████| 1302/1302 [00:56<00:00, 22.94it/s]\n",
      "Epoch 5 验证: 100%|██████████| 245/245 [00:02<00:00, 82.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, 训练损失: 0.3918, 验证损失: 0.3549, 耗时: 59.75s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 训练: 100%|██████████| 1302/1302 [00:58<00:00, 22.26it/s]\n",
      "Epoch 6 验证: 100%|██████████| 245/245 [00:02<00:00, 82.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, 训练损失: 0.3769, 验证损失: 0.3462, 耗时: 61.47s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.76it/s]\n",
      "Epoch 7 验证: 100%|██████████| 245/245 [00:03<00:00, 79.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, 训练损失: 0.3642, 验证损失: 0.3420, 耗时: 62.93s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 训练: 100%|██████████| 1302/1302 [01:20<00:00, 16.21it/s]\n",
      "Epoch 8 验证: 100%|██████████| 245/245 [00:04<00:00, 59.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, 训练损失: 0.3522, 验证损失: 0.3737, 耗时: 84.46s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 训练: 100%|██████████| 1302/1302 [01:14<00:00, 17.57it/s]\n",
      "Epoch 9 验证: 100%|██████████| 245/245 [00:04<00:00, 60.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, 训练损失: 0.3444, 验证损失: 0.3250, 耗时: 78.14s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 训练: 100%|██████████| 1302/1302 [01:13<00:00, 17.78it/s]\n",
      "Epoch 10 验证: 100%|██████████| 245/245 [00:03<00:00, 77.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, 训练损失: 0.3377, 验证损失: 0.3216, 耗时: 76.41s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 训练: 100%|██████████| 1302/1302 [01:06<00:00, 19.49it/s]\n",
      "Epoch 11 验证: 100%|██████████| 245/245 [00:03<00:00, 69.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, 训练损失: 0.3301, 验证损失: 0.3113, 耗时: 70.36s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 训练: 100%|██████████| 1302/1302 [01:17<00:00, 16.78it/s]\n",
      "Epoch 12 验证: 100%|██████████| 245/245 [00:03<00:00, 62.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, 训练损失: 0.3235, 验证损失: 0.3259, 耗时: 81.56s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 训练: 100%|██████████| 1302/1302 [01:15<00:00, 17.24it/s]\n",
      "Epoch 13 验证: 100%|██████████| 245/245 [00:03<00:00, 74.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, 训练损失: 0.3160, 验证损失: 0.2945, 耗时: 78.82s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 训练: 100%|██████████| 1302/1302 [01:10<00:00, 18.43it/s]\n",
      "Epoch 14 验证: 100%|██████████| 245/245 [00:03<00:00, 78.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, 训练损失: 0.3124, 验证损失: 0.3332, 耗时: 73.77s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 训练: 100%|██████████| 1302/1302 [01:16<00:00, 17.12it/s]\n",
      "Epoch 15 验证: 100%|██████████| 245/245 [00:03<00:00, 73.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, 训练损失: 0.3081, 验证损失: 0.2940, 耗时: 79.40s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 训练: 100%|██████████| 1302/1302 [01:08<00:00, 18.98it/s]\n",
      "Epoch 16 验证: 100%|██████████| 245/245 [00:03<00:00, 76.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, 训练损失: 0.3042, 验证损失: 0.3013, 耗时: 71.81s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 训练: 100%|██████████| 1302/1302 [01:02<00:00, 20.77it/s]\n",
      "Epoch 17 验证: 100%|██████████| 245/245 [00:03<00:00, 78.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, 训练损失: 0.3004, 验证损失: 0.2942, 耗时: 65.81s\n",
      "早停计数器: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 训练: 100%|██████████| 1302/1302 [01:05<00:00, 19.92it/s]\n",
      "Epoch 18 验证: 100%|██████████| 245/245 [00:03<00:00, 78.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, 训练损失: 0.2981, 验证损失: 0.2946, 耗时: 68.50s\n",
      "早停计数器: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 训练: 100%|██████████| 1302/1302 [01:12<00:00, 17.88it/s]\n",
      "Epoch 19 验证: 100%|██████████| 245/245 [00:03<00:00, 77.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, 训练损失: 0.2955, 验证损失: 0.3045, 耗时: 75.95s\n",
      "早停计数器: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 训练: 100%|██████████| 1302/1302 [01:06<00:00, 19.48it/s]\n",
      "Epoch 20 验证: 100%|██████████| 245/245 [00:03<00:00, 72.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, 训练损失: 0.2928, 验证损失: 0.2966, 耗时: 70.24s\n",
      "早停计数器: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 训练: 100%|██████████| 1302/1302 [01:04<00:00, 20.32it/s]\n",
      "Epoch 21 验证: 100%|██████████| 245/245 [00:03<00:00, 67.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, 训练损失: 0.2906, 验证损失: 0.2960, 耗时: 67.73s\n",
      "早停计数器: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 训练: 100%|██████████| 1302/1302 [01:02<00:00, 21.00it/s]\n",
      "Epoch 22 验证: 100%|██████████| 245/245 [00:03<00:00, 77.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, 训练损失: 0.2784, 验证损失: 0.2896, 耗时: 65.18s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.87it/s]\n",
      "Epoch 23 验证: 100%|██████████| 245/245 [00:03<00:00, 77.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, 训练损失: 0.2759, 验证损失: 0.3089, 耗时: 62.71s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 训练: 100%|██████████| 1302/1302 [00:58<00:00, 22.21it/s]\n",
      "Epoch 24 验证: 100%|██████████| 245/245 [00:03<00:00, 77.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, 训练损失: 0.2748, 验证损失: 0.2945, 耗时: 61.79s\n",
      "早停计数器: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 训练: 100%|██████████| 1302/1302 [01:04<00:00, 20.29it/s]\n",
      "Epoch 25 验证: 100%|██████████| 245/245 [00:03<00:00, 81.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, 训练损失: 0.2738, 验证损失: 0.2856, 耗时: 67.19s\n",
      "模型已保存至: icial_uv_rpe_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.75it/s]\n",
      "Epoch 26 验证: 100%|██████████| 245/245 [00:03<00:00, 79.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, 训练损失: 0.2723, 验证损失: 0.2887, 耗时: 62.94s\n",
      "早停计数器: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 训练: 100%|██████████| 1302/1302 [01:00<00:00, 21.56it/s]\n",
      "Epoch 27 验证: 100%|██████████| 245/245 [00:03<00:00, 78.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, 训练损失: 0.2723, 验证损失: 0.2968, 耗时: 63.55s\n",
      "早停计数器: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.78it/s]\n",
      "Epoch 28 验证: 100%|██████████| 245/245 [00:03<00:00, 79.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, 训练损失: 0.2698, 验证损失: 0.2881, 耗时: 62.89s\n",
      "早停计数器: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 训练: 100%|██████████| 1302/1302 [01:00<00:00, 21.45it/s]\n",
      "Epoch 29 验证: 100%|██████████| 245/245 [00:03<00:00, 68.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, 训练损失: 0.2687, 验证损失: 0.3044, 耗时: 64.26s\n",
      "早停计数器: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 训练: 100%|██████████| 1302/1302 [01:02<00:00, 20.94it/s]\n",
      "Epoch 30 验证: 100%|██████████| 245/245 [00:03<00:00, 73.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, 训练损失: 0.2692, 验证损失: 0.2905, 耗时: 65.51s\n",
      "早停计数器: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 训练: 100%|██████████| 1302/1302 [01:02<00:00, 20.82it/s]\n",
      "Epoch 31 验证: 100%|██████████| 245/245 [00:03<00:00, 79.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, 训练损失: 0.2677, 验证损失: 0.2885, 耗时: 65.63s\n",
      "早停计数器: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.81it/s]\n",
      "Epoch 32 验证: 100%|██████████| 245/245 [00:03<00:00, 79.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, 训练损失: 0.2604, 验证损失: 0.2911, 耗时: 62.79s\n",
      "早停计数器: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 训练: 100%|██████████| 1302/1302 [01:00<00:00, 21.56it/s]\n",
      "Epoch 33 验证: 100%|██████████| 245/245 [00:03<00:00, 79.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, 训练损失: 0.2599, 验证损失: 0.2917, 耗时: 63.47s\n",
      "早停计数器: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.94it/s]\n",
      "Epoch 34 验证: 100%|██████████| 245/245 [00:03<00:00, 79.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, 训练损失: 0.2594, 验证损失: 0.2900, 耗时: 62.45s\n",
      "早停计数器: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 训练: 100%|██████████| 1302/1302 [00:59<00:00, 21.80it/s]\n",
      "Epoch 35 验证: 100%|██████████| 245/245 [00:03<00:00, 73.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, 训练损失: 0.2581, 验证损失: 0.2940, 耗时: 63.07s\n",
      "早停计数器: 10/10\n",
      "触发早停！训练结束。\n",
      "\n",
      "模型总训练时间: 2361.68 秒\n",
      "总训练时间: 0小时 39分钟 21.68秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 6. 训练和验证循环\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- 步骤3: 开始模型训练 ---\")\n",
    "best_val_loss = float('inf') # 记录最佳验证损失\n",
    "early_stopping_counter = 0 # 早停计数器\n",
    "\n",
    "model_quantiles = model.quantiles_to_predict # 从模型获取需要预测的分位数列表\n",
    "\n",
    "# 记录总训练开始时间 (新增)\n",
    "total_train_start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    train_loss = 0.0\n",
    "    epoch_start_time = time.time() # 记录当前epoch的开始时间\n",
    "    \n",
    "    # 使用tqdm显示训练进度条\n",
    "    for batch_idx, (x_high, x_weather, x_low, *y_targets) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} 训练\")):\n",
    "        # 将数据移动到指定设备\n",
    "        x_high, x_weather, x_low = x_high.to(device), x_weather.to(device), x_low.to(device)\n",
    "        y_targets_on_device = [y.to(device) for y in y_targets] # 将所有目标张量也移动到设备\n",
    "\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        \n",
    "        predictions_dict = model(x_high, x_weather, x_low) # 模型前向传播\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        # 对每个目标预测步长计算并累加分位数损失\n",
    "        for i, name in enumerate(model.target_steps_names):\n",
    "            batch_loss += quantile_loss(y_targets_on_device[i], predictions_dict[name], model_quantiles)\n",
    "        \n",
    "        batch_loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新模型参数\n",
    "        train_loss += batch_loss.item() # 累加批次损失\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) # 计算平均训练损失\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval() # 设置模型为评估模式 (不计算梯度，不应用dropout等)\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): # 在此块内禁用梯度计算\n",
    "        for x_high, x_weather, x_low, *y_targets in tqdm(val_loader, desc=f\"Epoch {epoch+1} 验证\"):\n",
    "            x_high, x_weather, x_low = x_high.to(device), x_weather.to(device), x_low.to(device)\n",
    "            y_targets_on_device = [y.to(device) for y in y_targets]\n",
    "\n",
    "            predictions_dict = model(x_high, x_weather, x_low)\n",
    "            \n",
    "            batch_val_loss = 0.0\n",
    "            for i, name in enumerate(model.target_steps_names):\n",
    "                batch_val_loss += quantile_loss(y_targets_on_device[i], predictions_dict[name], model_quantiles)\n",
    "            val_loss += batch_val_loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader) # 计算平均验证损失\n",
    "    \n",
    "    epoch_end_time = time.time() # 记录当前epoch的结束时间\n",
    "    epoch_duration = epoch_end_time - epoch_start_time # 计算当前epoch持续时间\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, 训练损失: {avg_train_loss:.4f}, 验证损失: {avg_val_loss:.4f}, 耗时: {epoch_duration:.2f}s\")\n",
    "\n",
    "    scheduler.step(avg_val_loss) # 根据验证损失调整学习率\n",
    "\n",
    "    # 早停机制检查\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0 # 重置计数器\n",
    "        torch.save(model.state_dict(), MODEL_FILE_PATH) # 保存最佳模型\n",
    "        print(f\"模型已保存至: {MODEL_FILE_PATH}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"早停计数器: {early_stopping_counter}/{PATIENCE}\")\n",
    "        if early_stopping_counter >= PATIENCE:\n",
    "            print(\"触发早停！训练结束。\")\n",
    "            break\n",
    "\n",
    "# 记录总训练结束时间 (新增)\n",
    "total_train_end_time = time.time()\n",
    "total_train_duration = total_train_end_time - total_train_start_time\n",
    "\n",
    "# 打印总训练时间 (新增)\n",
    "print(f\"\\n模型总训练时间: {total_train_duration:.2f} 秒\")\n",
    "# 可以进一步转换为更易读的格式，例如小时、分钟\n",
    "hours, rem = divmod(total_train_duration, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"总训练时间: {int(hours)}小时 {int(minutes)}分钟 {seconds:.2f}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 步骤4: 正在测试集上评估模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "测试集预测: 100%|██████████| 82/82 [00:01<00:00, 60.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 正在计算评估指标 ---\n",
      "\n",
      "--- t_plus_3 的指标 (MIMO 策略) ---\n",
      "MAE: 0.0690 kW\n",
      "RMSE: 0.2061 kW\n",
      "nMAE: 0.0536\n",
      "nRMSE: 0.1601\n",
      "SMAPE: 0.09\n",
      "\n",
      "--- t_plus_6 的指标 (MIMO 策略) ---\n",
      "MAE: 0.0832 kW\n",
      "RMSE: 0.2383 kW\n",
      "nMAE: 0.0646\n",
      "nRMSE: 0.1851\n",
      "SMAPE: 0.12\n",
      "\n",
      "--- t_plus_12 的指标 (MIMO 策略) ---\n",
      "MAE: 0.1009 kW\n",
      "RMSE: 0.2737 kW\n",
      "nMAE: 0.0784\n",
      "nRMSE: 0.2126\n",
      "SMAPE: 0.15\n",
      "\n",
      "--- t_plus_24 的指标 (MIMO 策略) ---\n",
      "MAE: 0.1470 kW\n",
      "RMSE: 0.3382 kW\n",
      "nMAE: 0.1142\n",
      "nRMSE: 0.2627\n",
      "SMAPE: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7. 模型在测试集上的评估\n",
    "# =============================================================================\n",
    "\n",
    "# --- SMAPE 计算函数 (新增) ---\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算对称平均绝对百分比误差 (SMAPE)。\n",
    "    参考论文公式: SMAPE = (1/n) * sum(|y_i - y_hat_i| / ((|y_i| + |y_hat_i| + 0.1) / 2)) [cite: 1089]\n",
    "    \"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred) + 0.1) / 2\n",
    "    # 避免除以零，虽然分母已经加了0.1，但在极端情况下仍需谨慎\n",
    "    # 对于分母为0的情况（理论上此处不会发生），返回0或np.nan，这里选择0以避免NaN影响平均\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) # SMAPE通常表示为百分比\n",
    "\n",
    "print(\"\\n--- 步骤4: 正在测试集上评估模型 ---\")\n",
    "# 加载性能最佳的模型\n",
    "model.load_state_dict(torch.load(MODEL_FILE_PATH))\n",
    "model.eval() # 设置模型为评估模式\n",
    "\n",
    "# Store predictions for each target step and quantile\n",
    "test_predictions_raw = {name: [] for name in model.target_steps_names}\n",
    "true_values_raw = {name: [] for name in model.target_steps_names} # 存储归一化后的真实值\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_high, x_weather, x_low, *y_targets_scaled in tqdm(test_loader, desc=\"测试集预测\"):\n",
    "        x_high, x_weather, x_low = x_high.to(device), x_weather.to(device), x_low.to(device)\n",
    "        \n",
    "        predictions_dict = model(x_high, x_weather, x_low)\n",
    "        \n",
    "        for i, name in enumerate(model.target_steps_names):\n",
    "            test_predictions_raw[name].append(predictions_dict[name].cpu().numpy())\n",
    "            true_values_raw[name].append(y_targets_scaled[i].cpu().numpy()) # y_targets_scaled 已经是归一化后的真实值\n",
    "\n",
    "# Concatenate all batch predictions and true values\n",
    "for name in model.target_steps_names:\n",
    "    test_predictions_raw[name] = np.concatenate(test_predictions_raw[name], axis=0)\n",
    "    true_values_raw[name] = np.concatenate(true_values_raw[name], axis=0)\n",
    "\n",
    "# Inverse transform predictions and true values to original scale for metric calculation\n",
    "print(\"\\n--- 正在计算评估指标 ---\")\n",
    "results = {} # 存储最终评估结果\n",
    "\n",
    "for i, s in enumerate(TARGET_STEPS):\n",
    "    name = f't_plus_{s}'\n",
    "    \n",
    "    # 逆归一化每个分位数的预测值\n",
    "    predictions_original_scale = np.zeros_like(test_predictions_raw[name])\n",
    "    for q_idx in range(len(model.quantiles_to_predict)):\n",
    "        predictions_original_scale[:, q_idx] = scalers_y[name].inverse_transform(test_predictions_raw[name][:, q_idx:q_idx+1]).flatten()\n",
    "\n",
    "    # 逆归一化真实值\n",
    "    true_original_scale = scalers_y[name].inverse_transform(true_values_raw[name].reshape(-1, 1)).flatten()\n",
    "\n",
    "    # 获取中位数预测值 (0.5 分位数)，通常用于点预测评估\n",
    "    median_pred_idx = model.quantiles_to_predict.index(0.5)\n",
    "    median_predictions = predictions_original_scale[:, median_pred_idx]\n",
    "    \n",
    "    # 计算MAE和RMSE (使用中位数预测)\n",
    "    mae = mean_absolute_error(true_original_scale, median_predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(true_original_scale, median_predictions))\n",
    "    \n",
    "    # 计算nMAE和nRMSE (归一化指标)\n",
    "    mean_y = np.mean(true_original_scale)\n",
    "    range_y = np.max(true_original_scale) - np.min(true_original_scale)\n",
    "    nmae = mae / mean_y if mean_y != 0 else float('inf')\n",
    "    nrmse = rmse / mean_y if mean_y != 0 else float('inf')\n",
    "\n",
    "    # 计算SMAPE (新增)\n",
    "    _smape = smape(true_original_scale, median_predictions)\n",
    "\n",
    "    results[name] = {\n",
    "        'MAE (kW)': mae,\n",
    "        'RMSE (kW)': rmse,\n",
    "        'nMAE': nmae,\n",
    "        'nRMSE': nrmse,\n",
    "        'SMAPE': _smape, # 新增SMAPE结果\n",
    "        '真实值 (kW)': true_original_scale,\n",
    "        '中位数预测 (kW)': median_predictions,\n",
    "        '所有分位数预测 (kW)': predictions_original_scale\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- {name} 的指标 (MIMO 策略) ---\")\n",
    "    print(f\"MAE: {mae:.4f} kW\")\n",
    "    print(f\"RMSE: {rmse:.4f} kW\")\n",
    "    print(f\"nMAE: {nmae:.4f}\")\n",
    "    print(f\"nRMSE: {nrmse:.4f}\")\n",
    "    print(f\"SMAPE: {_smape:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
